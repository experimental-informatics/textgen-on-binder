{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8085bfaa-1569-48be-a49e-511696f04805",
   "metadata": {},
   "source": [
    "# GPT-2 on Trump Speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce381cf3-19b2-480c-b267-ceddea418861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install aitextgen\n",
    "from aitextgen.TokenDataset import TokenDataset\n",
    "from aitextgen.tokenizers import train_tokenizer\n",
    "from aitextgen.utils import GPT2ConfigCPU\n",
    "from aitextgen import aitextgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b5bc0d9-e0c0-4b25-92c6-1f0b24e9ac41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name of the downloaded Shakespeare text for training\n",
    "# file location: https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
    "file_name = \"trump-speeches.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce74faf1-718c-46bb-b7db-cfc6bd9c2d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a custom BPE Tokenizer on the downloaded text\n",
    "# This will save one file: `aitextgen.tokenizer.json`, which contains the\n",
    "# information needed to rebuild the tokenizer.\n",
    "train_tokenizer(file_name)\n",
    "tokenizer_file = \"aitextgen.tokenizer.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc4cf292-5f65-424a-9d1a-0183b50a18b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT2ConfigCPU is a mini variant of GPT-2 optimized for CPU-training\n",
    "# e.g. the # of input tokens here is 64 vs. 1024 for base GPT-2.\n",
    "config = GPT2ConfigCPU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b25983f1-f19f-4c87-907b-dfcc3d060945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate aitextgen using the created tokenizer and config\n",
    "ai = aitextgen(tokenizer_file=tokenizer_file, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f214b91-6484-49de-9093-bcf03dfcbdb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e4551e0ee144ff8bca3ec04c6be6152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=7678.0), HTML(value='')), layout=Layout(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# You can build datasets for training by creating TokenDatasets,\n",
    "# which automatically processes the dataset with the appropriate size.\n",
    "data = TokenDataset(file_name, tokenizer_file=tokenizer_file, block_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f57ba3d-954f-4f3e-9ab7-b4ed134f61d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin already exists in /trained_model and will be overwritten!\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f94ecd623de43ebbb1aa2a498186b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=5000.0), HTML(value='')), layout=Layout(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m5,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      ". It’s a great.\n",
      "\n",
      "We’re going to have to be in the history of trade. We’re going to be a very happy.\n",
      "It’s going to be a greatest. Were going to be a great trade deal. It’s a dish\n",
      "==========\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model! It will save pytorch_model.bin periodically and after completion to the `trained_model` folder.\n",
    "# On a 2020 8-core iMac, this took ~25 minutes to run.\n",
    "ai.train(data, \n",
    "         batch_size=8, \n",
    "         num_steps=500, \n",
    "         generate_every=500, \n",
    "         save_every=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8923e237-cb4a-4b28-9643-5e442ec44073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mMake America Great Again\u001b[0m.\n",
      "We need such a look at what China.\n",
      "We are going on the best place we need very interesting, very strongly. Thank you. Thank you very much, very much, very many of the greatest deal.\n",
      "And we have a great\n",
      "==========\n",
      "\u001b[1mMake America Great Again\u001b[0m. I mean, it’s a great stage. But I’m not going to make a place.\n",
      "And I’m going to be good. I’d want to thank you.\n",
      "\n",
      "\n",
      "\n",
      "I’m a lot of things. I\n",
      "==========\n",
      "\u001b[1mMake America Great Again\u001b[0m, and he’s a very many honorrible. And he said, \"Who does it’s a tonight. This even a lot of months they’re not going to do it.\n",
      "And we’re going to t\n",
      "==========\n",
      "\u001b[1mMake America Great Again\u001b[0mly and I'dTRUSTIGOT MASNINGS. I GOT TAKE. I'E OF OVER. SHOULD NOT ROT A -- THIS LEVER OVER T\n",
      "==========\n",
      "\u001b[1mMake America Great Again\u001b[0ms a big believate. Webia. I think we’re going to be a good military. We have another and we’re going to be a lot of it. We have a great election. We have fire polls\n",
      "==========\n",
      "\u001b[1mMake America Great Again\u001b[0m, Flor Pennessoland, I don’t have been taken care of our eachiplish, and many of people of the moneys infrastrucationals.\n",
      "In fact, In\n",
      "==========\n",
      "\u001b[1mMake America Great Again\u001b[0m – I’m going to win. I’ve got great for a lot — week you know what, it is not going to happen.\n",
      "And they’re going to be hither be a lot of money of money than that’s going to be\n",
      "==========\n",
      "\u001b[1mMake America Great Again\u001b[0m, of immigration.\n",
      "And we have, I was in the world and Indiana want to turn us down – the MiddcCain of our enemies, so many wealanchallengy a law\n",
      "==========\n",
      "\u001b[1mMake America Great Again\u001b[0ms. So I’m not going to treate a lot of people. The emplan beautely. I’m not being taken care of our vets. I’m going to be. I’m going to be a lot\n",
      "==========\n",
      "\u001b[1mMake America Great Again\u001b[0m Peetoenn. It was a night.\n",
      "If weapon. Inew that, I just had a very wait of breaker and a lot of it. And I did, \"Hey the most of our\n"
     ]
    }
   ],
   "source": [
    "# Generate text from it!\n",
    "ai.generate(10, prompt=\"Make America Great Again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17ff4867-e32d-4258-8d31-52973742ab9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ai2 = aitextgen(model_folder=\"trained_model\",\\n                tokenizer_file=\"aitextgen.tokenizer.json\")\\n\\nai2.generate(10, prompt=\"ROMEO:\")'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can also use the already trained model in the folder\n",
    "# providing the folder containing the pytorch_model.bin model weights + the config, and providing the tokenizer.\n",
    "\n",
    "'''ai2 = aitextgen(model_folder=\"trained_model\",\n",
    "                tokenizer_file=\"aitextgen.tokenizer.json\")\n",
    "\n",
    "ai2.generate(10, prompt=\"Look, I\")'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
