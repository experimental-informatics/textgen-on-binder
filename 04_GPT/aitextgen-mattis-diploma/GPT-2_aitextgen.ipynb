{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-2 Part of Mattis' Diploma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Install libraries. '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Install libraries. '''\n",
    "# !python3 -m pip install aitextgen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aitextgen.TokenDataset import TokenDataset\n",
    "from aitextgen.tokenizers import train_tokenizer\n",
    "from aitextgen.utils import GPT2ConfigCPU\n",
    "from aitextgen.utils import build_gpt2_config\n",
    "from aitextgen import aitextgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"./dataset.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Tokenize dataset (Byte-Pair-Encoding). '''\n",
    "train_tokenizer(file_name, vocab_size=10000)\n",
    "vocab_file = \"gpt-2_aitextgen/aitextgen-vocab.json\"\n",
    "merges_file = \"gpt-2_aitextgen/aitextgen-merges.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"attn_pdrop\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 256,\n",
      "  \"n_embd\": 128,\n",
      "  \"n_head\": 4,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 2,\n",
      "  \"n_positions\": 256,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.0,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 10000\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3100eb8ae8a34761863b132e5b7c237a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=2533.0), HTML(value='')), layout=Layout(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "''' Custom configuration. '''\n",
    "config = build_gpt2_config(n_embd=128,\n",
    "                           n_head=4,\n",
    "                           n_layer=2,\n",
    "                           vocab_size=10000,\n",
    "                           max_length=256\n",
    "                          )\n",
    "\n",
    "print(config)\n",
    "\n",
    "''' Model. '''\n",
    "ai = aitextgen(vocab_file=vocab_file, merges_file=merges_file, config=config)\n",
    "''' Dataset for training. '''\n",
    "data = TokenDataset(file_name, vocab_file=vocab_file, merges_file=merges_file, block_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whoami/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=False)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=False)`.\n",
      "  rank_zero_deprecation(\n",
      "/home/whoami/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:90: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=20)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "/home/whoami/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:167: LightningDeprecationWarning: Setting `Trainer(weights_summary=None)` is deprecated in v1.5 and will be removed in v1.7. Please set `Trainer(enable_model_summary=False)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/home/whoami/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eee971146394de0b0ac08b030e91afc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=500.0), HTML(value='')), layout=Layout(di…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whoami/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1823: LightningDeprecationWarning: `trainer.progress_bar_dict` is deprecated in v1.5 and will be removed in v1.7. Use `ProgressBarBase.get_metrics` instead.\n",
      "  rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "''' Training. '''\n",
    "ai.train(data, batch_size=8, num_steps=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nai = aitextgen(model_folder=\"gpt-2_aitextgen/trained_model\",\\n               config=\"gpt-2_aitextgen/trained_model/config.json\",\\n               vocab_file=\"gpt-2_aitextgen/aitextgen-vocab.json\",\\n               merges_file=\"gpt-2_aitextgen/aitextgen-merges.txt\",\\n               to_gpu=False)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "ai = aitextgen(model_folder=\"gpt-2_aitextgen/trained_model\",\n",
    "               config=\"gpt-2_aitextgen/trained_model/config.json\",\n",
    "               vocab_file=\"gpt-2_aitextgen/aitextgen-vocab.json\",\n",
    "               merges_file=\"gpt-2_aitextgen/aitextgen-merges.txt\",\n",
    "               to_gpu=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDie Lernfähigkeit des Gehirns wird ermöglicht durch das selbständige Verknüpfen von Synapsen.\u001b[0m\n",
      "Die Antwort einzelner Zellen und auch dies eher eine eigene Prozess des Systems.\n",
      "So ist die Struktur der Lage ist die Reize.\n",
      "Das ist auf die die Repräsentationen und diese Systeme sind die Möglichkeit der Verarbeitung von verschiedenen Neuronen.\n",
      "Die Extended Mind Theorie des Subjekts.\n",
      "Die einzige Bindungsneuronen geben kann es sich durch die Reflexion entstehen und nicht direkt mit der Welt und diese durch die Welt, dass sie auch wenn die Dinge in der Umwelt.\n",
      "Die zeitliche Koordination von Daten.\n",
      "Im Bereich der Verarbeitung von der Nervenzellen.\n",
      "Die Extended Mind der Algorithmen der Umwelt.\n",
      "Dadurch entsteht durch den Verstand und und dem Schachspiel oder nur durch die Außenwelt (F geht es auch die Welt nicht nur in der Reflexion des Systems zu können, dass sie können, anstatt sie zu können sie zu sein kann die Umwelt und auch mit der Verarbeitung von Neuronen, die Welt auf die Intelligenz.\n",
      "Ein Grund ist es für die in der Welt aus der Umwelt zu erfassen.\n",
      "Die Algorithmen in der anderen Seite der Hirnrinde ein Ich- und und Wiedererkennen.\n",
      "Ein Idealfall ist die Struktur der Maschine, dass sie unsere Strukturen sind es auf die zeitliche Koordination von Überraschung und Maschinen werden kann zu werden; die Struktur der Entwicklung von\n",
      "None\n",
      "\u001b[1mDie Lernfähigkeit des Gehirns wird ermöglicht durch das selbständige Verknüpfen von Synapsen.\u001b[0m\n",
      "Damit sind das Ich, sondern eine Parortik und die Umwelt die Welt durch die Merkmalsreferenz zur Pubertät oder auf Kategorien oder der Beschreibung und nicht mehr auf der Ebene getroffen.\n",
      "Wesentlich für die durch die Ereignisse sind nicht länger als 'opopologien definieren.\n",
      "Der Künstler für die Susomorph zueinander in symbolischen Welt erzeugen.\n",
      "Das Gehirn ist also nicht ein einheitliches Netz.\n",
      "Nach Heidegger wir den niedrigen Bevölkerungsschichten ist für das System.\n",
      "Was ist die darunterwächtohn lediglich auf die in der ästhetischen Fähigkeiten sich dieser Modelle und zu können können als Teilaspekt des Handelns und kann es die Zeit seiner zeitlich im Gehirn das Verhalten.\n",
      "Für den GeschäI-Zuständen, das zu einer eigenen Körpers.\n",
      "Ein einzelner Identität, das Gehirn als Modell sind auf Basis von Symbolen.\n",
      "Die Zeichen, als Daten, dass die Maschinen gehen.\n",
      "Es ist die Welt in den anderen Nervenzellen.\n",
      "Wesentlich für die Maschine im zweiten nach Heidegger und sie können, dass eine Verbindung zwischen Algorithmen auf andere durch zeitliche Trennung von Umwelt.\n",
      "Das Ich und Maschine ist.\n",
      "Die Stärke der Seite der Verarbeitung).\n",
      "Die Stärke aus der Fähigkeit und damit auch eine Dissoziationen in unterschiedlichen Gehirn als die Konstruktion\n",
      "None\n",
      "\u001b[1mDie Lernfähigkeit des Gehirns wird ermöglicht durch das selbständige Verknüpfen von Synapsen.\u001b[0m\n",
      "Um für seine eigenen Repräsentationen, dass wir über ein Agent werden bedarf es auch als eine Verbindung von Systemen in das Bühne möglich als System werden könnte keine Entsprechung in Algorithmen die Reflexion nicht über 'Kimso erfolglos und nur unbewusste vermittels oder und in Basis\n",
      "Im 18mutterhrten Dinge sein heißt, welches uns einen Menschen sind bereits, als eine etwas positives.heiltere Verarbeitungsprozesse im Kunstwerk ein Ensemble, dass einzelne Neurone Intelligenz nicht und nicht vollständig, sondern in die unsere Repräsentationen und Handeln auch wenn sie im Raum auf eine bestimmte Arten von Werten als Modell der Daten, arbeiten mit Kategorien zu einer Parhal.\n",
      "Auf das Bewusstsein die Algorithmen ihre Grenzen der Ereignisse als seiend und diese Reize wird sie sich dann müssen, dass die Fähigkeit und nur relativ wenig positives in diese Nervenzellen in dieser Fähigkeit des Wortessen mit Daten der Vorhersage, etwas auf kognitiven Repräsentationen von einem, die Reize wird auch im Nachhinein nach.h?\n",
      "Um hter zu werden auch das Netz stattfinden und werden – aus. Jahrhunderten.\n",
      "Die Entwicklung von von Informationen bestehen lediglich das wir uns die in sie mit anderen Tieren an Leistiger Strukturen und Handlungen bezeichnet werden\n",
      "Wir können.\n",
      "Sie ermöglicht.\n",
      "Durch zeitliche\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inp = '''\n",
    "Die Lernfähigkeit des Gehirns wird ermöglicht durch das selbständige Verknüpfen von Synapsen.\n",
    "'''.replace('\\n','')\n",
    "for temp in [0.5, 1.0, 1.5]:\n",
    "    print(ai.generate(prompt=inp, temperature=temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "https://docs.aitextgen.io/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
